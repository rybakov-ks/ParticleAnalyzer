import json
from typing import Dict, List, Tuple, Literal
import pandas as pd
from openai import OpenAI
from huggingface_hub import InferenceClient
from particleanalyzer.core.language_context import LanguageContext
from particleanalyzer.core.languages import translations


class LLMAnalysis:
    def __init__(
        self,
        api_key: str,
        provider: Literal["openrouter", "huggingface"] = "openrouter",
        huggingface_model: str = "fireworks-ai",
        openrouter_model: str = "deepseek/deepseek-chat:free",
    ):
        self.provider = provider
        self.api_key = api_key
        self.stats: Dict[str, Dict[str, float]] = {}

        if provider == "openrouter":
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=api_key,
            )
            self.model = openrouter_model
        elif provider == "huggingface":
            self.client = InferenceClient(provider=huggingface_model, api_key=api_key)
            self.model = huggingface_model
        else:
            raise ValueError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä. –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: 'openrouter', 'huggingface'")

    def load_data(self, df: pd.DataFrame) -> None:
        required_columns = {
            self._get_translation("–ü–∞—Ä–∞–º–µ—Ç—Ä"),
            self._get_translation("–°—Ä–µ–¥–Ω–µ–µ"),
            self._get_translation("–ú–µ–¥–∏–∞–Ω–∞"),
            self._get_translation("–ú–∞–∫—Å–∏–º—É–º"),
            self._get_translation("–ú–∏–Ω–∏–º—É–º"),
            self._get_translation("–°—Ä–µ–¥–Ω–µ–µ"),
        }
        if not required_columns.issubset(df.columns):
            raise ValueError(f"DataFrame –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: {required_columns}")

        self.stats = {
            row[self._get_translation("–ü–∞—Ä–∞–º–µ—Ç—Ä")]: {
                self._get_translation("–°—Ä–µ–¥–Ω–µ–µ"): row[self._get_translation("–°—Ä–µ–¥–Ω–µ–µ")],
                self._get_translation("–ú–µ–¥–∏–∞–Ω–∞"): row[self._get_translation("–ú–µ–¥–∏–∞–Ω–∞")],
                self._get_translation("–ú–∞–∫—Å–∏–º—É–º"): row[self._get_translation("–ú–∞–∫—Å–∏–º—É–º")],
                self._get_translation("–ú–∏–Ω–∏–º—É–º"): row[self._get_translation("–ú–∏–Ω–∏–º—É–º")],
                self._get_translation("–°—Ä–µ–¥–Ω–µ–µ"): row[self._get_translation("–°—Ä–µ–¥–Ω–µ–µ")],
            }
            for _, row in df.iterrows()
        }

    def analyze(self, df: pd.DataFrame, count_particles: int) -> List[Tuple[None, str]]:
        self.count_particles = count_particles
        if df.empty:
            return [(None, None)]
        self.lang = LanguageContext.get_language()
        self.load_data(df)
        try:
            prompt = self._build_prompt()
            response = self._get_llm_response(prompt)
            return self._format_response(response)
        except Exception as e:
            print(f"LLM analysis failed: {str(e)}")
            return [(None, None)]

    def _build_prompt(self) -> str:
        return f"""
        –¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤–µ–¥–µ–Ω–∏—è –∏ —Å–∫–∞–Ω–∏—Ä—É—é—â–µ–π —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –º–∏–∫—Ä–æ—Å–∫–æ–ø–∏–∏ —Å 10 –ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º.
        –ü—Ä–æ–≤–µ–¥–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –°–≠–ú –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ —Ä–∞–∑–º–µ—Ä–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö —á–∞—Å—Ç–∏—Ü.
        –í —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:
        - –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: –ø–ª–æ—â–∞–¥—å, –ø–µ—Ä–∏–º–µ—Ç—Ä, —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–π –¥–∏–∞–º–µ—Ç—Ä, –¥–∏–∞–º–µ—Ç—Ä –§–µ—Ä–µ—Ç–∞ (min, max, mean)
        - –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—Å–∏—Ç–µ—Ç
        - –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π/–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª –¥–∏–∞–º–µ—Ç—Ä–∞ –§–µ—Ä–µ—Ç–∞
        - –°—Ä–µ–¥–Ω—è—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–∏–∫—Å–µ–ª–µ–π —á–∞—Å—Ç–∏—Ü
        –ü—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–µ –æ–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∏ –º–µ–¥–∏–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –∞ –Ω–µ –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–∞–∫ —Ç—É–¥–∞ –º–æ–≥—É—Ç –ø–æ–ø–∞—Å—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–∏—Ü—ã.

        üîç **–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö –∞—Å–ø–µ–∫—Ç–∞—Ö:**
        1. **–†–∞–∑–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –Ω–∞–ª–∏—á–∏–µ –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—â–∏—Ö —Ñ—Ä–∞–∫—Ü–∏–π, —Ä–∞–∑–±—Ä–æ—Å (SD), —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ Max/Min.
        –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏—è —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∫–∞–∫ –≤ –º–∫–º —Ç–∞–∫ –∏ –≤ –ø–∏–∫—Å–µ–ª—è—Ö.
        2. **–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è** ‚Äî —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—Å–∏—Ç–µ—Ç, –æ–∫—Ä—É–≥–ª–æ—Å—Ç—å, –≤—ã—Ç—è–Ω—É—Ç–æ—Å—Ç—å (D‚Çò‚Çê‚Çì / D‚Çò·µ¢‚Çô)
        3. **–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è —á–∞—Å—Ç–∏—Ü** ‚Äî –µ—Å—Ç—å –ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –≤ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.

        üìã **–ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–∞–Ω–Ω—ã—Ö:**
        –í—Å–µ–≥–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ {self.count_particles} —á–∞—Å—Ç–∏—Ü. –°–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏:
        {json.dumps(self.stats, indent=2)}

        ‚úçÔ∏è **–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∞–Ω–∞–ª–∏–∑ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:**

        üî¨ **–ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑**:
        - –†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏—Ü: <–∞–Ω–∞–ª–∏–∑ –ø–æ D, SD, —Ä–∞–∑–±—Ä–æ—Å, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–∏—Ü>
        - –§–æ—Ä–º–∞: <–∞–Ω–∞–ª–∏–∑ –ø–æ e, –∞—Å–ø–µ–∫—Ç–Ω–æ–º—É –æ—Ç–Ω–æ—à–µ–Ω–∏—é>
        - –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: <–∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É–≥–ª–æ–≤>

        üß™ **–ú–∞—Ç–µ—Ä–∏–∞–ª–æ–≤–µ–¥—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã**:
        - <–≤–ª–∏—è–Ω–∏–µ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞ —Å–≤–æ–π—Å—Ç–≤–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞, –≤–æ–∑–º–æ–∂–Ω–æ–µ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ>

        üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
        - <–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –º–µ—Ç–æ–¥—ã –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞, –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –∞–Ω–æ–º–∞–ª–∏–π>

        –û—Ç–≤–µ—á–∞–π –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —è–∑—ã–∫–µ {self.lang}
        """

    def _get_llm_response(self, prompt: str):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        if self.provider == "openrouter":
            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "https://sem.rybakov-k.ru/",
                    "X-Title": "ParticleAnalyzer",
                },
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )
            return completion
        elif self.provider == "huggingface":
            return self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )

    def _format_response(self, response) -> List[Tuple[None, str]]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ–±–æ–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        if self.provider == "openrouter":
            analysis = response.choices[0].message.content
        elif self.provider == "huggingface":
            analysis = response.choices[0].message.content
        return [(None, analysis)]

    def _get_translation(self, text):
        return translations.get(self.lang, {}).get(text, text)