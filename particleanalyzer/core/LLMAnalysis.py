import json
from typing import Dict, List, Tuple, Literal
import pandas as pd
import numpy as np
from openai import OpenAI
from huggingface_hub import InferenceClient
from particleanalyzer.core.language_context import LanguageContext


class LLMAnalysis:
    def __init__(
        self,
        api_key: str,
        provider: Literal["openrouter", "huggingface"] = "openrouter",
    ):
        self.provider = provider
        self.api_key = api_key
        
        if self.api_key.startswith("hf_"):
            provider == "huggingface"
            self.client = InferenceClient(provider="fireworks-ai", api_key=api_key)
            self.model_list = ["deepseek-ai/DeepSeek-V3"]
        elif self.api_key.startswith("sk-or-"):
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=api_key,
            )
            self.model_list = ["deepseek/deepseek-chat:free", "deepseek/deepseek-chat-v3-0324", "google/gemini-2.0-flash-001", 
                                "openai/gpt-4o-mini"]
            provider == "openrouter"
        else:
            raise ValueError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä. –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: 'openrouter', 'huggingface'")
        
    def _calculate_stats(self, df: pd.DataFrame, num_bins: int = 5) -> Dict[str, Dict]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, —Å–æ—Ö—Ä–∞–Ω—è—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤"""
        stats = {
            "particles_count": len(df),
            "parameters": {}
        }
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            # –ë–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            stats["parameters"][col] = {
                "mean": float(df[col].mean()),
                "median": float(df[col].median()),
                "std": float(df[col].std()),
                "min": float(df[col].min()),
                "max": float(df[col].max()),
                "q1": df[col].quantile(0.25),
                "q3": df[col].quantile(0.75),
                "skewness": df[col].skew(),
                "kurtosis": df[col].kurtosis(),
                "histogram": self._create_histogram(df[col], num_bins)
            }
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã (–ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º)
            if "D‚Çò‚Çê‚Çì" in col and any("D‚Çò·µ¢‚Çô" in c for c in df.columns):
                stats["parameters"]["aspect_ratio"] = self._calc_aspect_ratio(df, num_bins)
                
            if "P [" in col and any("S [" in c for c in df.columns):
                stats["parameters"]["circularity"] = self._calc_circularity(df, num_bins)
        return stats

    def _create_histogram(self, data, num_bins):
        """–°–æ–∑–¥–∞–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É"""
        counts, bins = np.histogram(data, bins=num_bins)
        return {
            "bins": [float(x) for x in bins],
            "counts": [int(x) for x in counts]
        }

    def _calc_aspect_ratio(self, df, num_bins):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∞—Å–ø–µ–∫—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ"""
        dmax_col = [c for c in df.columns if "D‚Çò‚Çê‚Çì" in c][0]
        dmin_col = [c for c in df.columns if "D‚Çò·µ¢‚Çô" in c][0]
        ar = df[dmax_col] / df[dmin_col]
        return {
            "mean": float(ar.mean()),
            "median": float(ar.median()),
            "histogram": self._create_histogram(ar, num_bins)
        }

    def _calc_circularity(self, df, num_bins):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–∫—Ä—É–≥–ª–æ—Å—Ç—å"""
        p_col = [c for c in df.columns if "P [" in c][0]
        s_col = [c for c in df.columns if "S [" in c][0]
        circ = 4 * np.pi * df[s_col] / (df[p_col] ** 2)
        return {
            "mean": float(circ.mean()),
            "median": float(circ.median()),
            "histogram": self._create_histogram(circ, num_bins)
        }

    def analyze(self, df: pd.DataFrame, model_llm: str) -> List[Tuple[None, str]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç DataFrame —Å —á–∞—Å—Ç–∏—Ü–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã LLM"""
        self.lang = LanguageContext.get_language()
        
        if df.empty:
            return [(None, "No particles detected")]
            
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = self._calculate_stats(df)
        count_particles = len(df)
        
        try:
            prompt = self._build_prompt(stats, count_particles)
            self.model = model_llm
            response = self._get_llm_response(prompt)
            return self._format_response(response)
        except Exception as e:
            print(f"LLM analysis failed: {str(e)}")
            return [(None, f"Analysis error: {str(e)}")]

    def _build_prompt(self, stats, count_particles) -> str:
        return f"""
        –¢—ã ‚Äî –≤–µ–¥—É—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤–µ–¥–µ–Ω–∏–∏ –∏ —Å–∫–∞–Ω–∏—Ä—É—é—â–µ–π —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –º–∏–∫—Ä–æ—Å–∫–æ–ø–∏–∏ (–°–≠–ú) —Å 15-–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º. 
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º {count_particles} —á–∞—Å—Ç–∏—Ü.

        üìå **–ö–æ–Ω—Ç–µ–∫—Å—Ç**:
        - –î–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, –º–µ–¥–∏–∞–Ω—ã, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏ –¥—Ä.).
        - –†–∞–∑–º–µ—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å –≤ –º–∏–∫—Ä–æ–º–µ—Ç—Ä–∞—Ö –∏–ª–∏ –ø–∏–∫—Å–µ–ª—è—Ö.
        - –í–æ–∑–º–æ–∂–Ω—ã –∞–Ω–æ–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑-–∑–∞ –æ–±—Ä–µ–∑–∫–∏ —á–∞—Å—Ç–∏—Ü –ø–æ –∫—Ä–∞—è–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. 
        - **–í–∞–∂–Ω–æ**: –ö—Ä—É–ø–Ω—ã–µ —á–∞—Å—Ç–∏—Ü—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ ‚Äî **–Ω–µ —É–ø–æ–º–∏–Ω–∞–π –≤–ª–∏—è–Ω–∏–µ –æ–±—Ä–µ–∑–∫–∏ –≤ –∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–∏**.
        - –ù–µ –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞–π –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî **—Ç–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π**
        - –û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –±–µ–∑ —á–∏—Å–ª–æ–≤–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º.

        üî¨ **–ó–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞**:
        1. **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤** ‚Äî —Ç–∏–ø, —Ñ—Ä–∞–∫—Ü–∏–∏, –∞–Ω–æ–º–∞–ª–∏–∏, –ø–æ–ª–∏–¥–∏—Å–ø–µ—Ä—Å–Ω–æ—Å—Ç—å  
        2. **–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è** ‚Äî —Ñ–æ—Ä–º–∞, –≤—ã—Ç—è–Ω—É—Ç–æ—Å—Ç—å, –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å  
        3. **–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è** ‚Äî –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å
        4. **–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã** ‚Äî —É—á–∞—Å—Ç–∫–∏ —Å —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è–º–∏

        ‚úçÔ∏è **–§–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞ (—è–∑—ã–∫: {self.lang})** ‚Äî –±–µ–∑ –ª–∏—à–Ω–∏—Ö –æ—Ç—Å—Ç—É–ø–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –∏ —Å–º–∞–π–ª–∏–∫–∏-–∏–∫–æ–Ω–∫–∏:
        
        üå°Ô∏è **–†–∞–∑–º–µ—Ä–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
        - **–†–∞–∑–º–µ—Ä**: <–¥–∏–∞–º–µ—Ç—Ä, –¥–∏–∞–ø–∞–∑–æ–Ω—ã, –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—â–∏–µ —Ñ—Ä–∞–∫—Ü–∏–∏>  
        - **–¢–∏–ø —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è**: <–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ / –±–∏–º–æ–¥–∞–ª—å–Ω–æ–µ / –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–µ>  
        - **–ê–Ω–æ–º–∞–ª–∏–∏**: <–≤—ã–±—Ä–æ—Å—ã, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã, –≤–ª–∏—è–Ω–∏–µ –æ–±—Ä–µ–∑–∫–∏>  
        - **–ü–æ–ª–∏–¥–∏—Å–ø–µ—Ä—Å–Ω–æ—Å—Ç—å**: <–Ω–∏–∑–∫–∞—è / —É–º–µ—Ä–µ–Ω–Ω–∞—è / –≤—ã—Å–æ–∫–∞

        üîµ **–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è**:
        - **–ü—Ä–µ–æ–±–ª–∞–¥–∞—é—â–∞—è —Ñ–æ—Ä–º–∞**: <–æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ circularity, aspect_ratio, —ç–∫—Å—Ü–µ–Ω—Ç—Ä–∏—Å–∏—Ç–µ—Ç–µ e>  
        - **–û–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å**: <–æ—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Ñ–æ—Ä–º>  
        - **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**: <–Ω–µ–æ–±—ã—á–Ω—ã–µ —Ñ–æ—Ä–º—ã, –≥—Ä—É–ø–ø—ã, –¥–µ—Ñ–µ–∫—Ç—ã>  

        üß≠ **–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è**:
        - **–¢–∏–ø —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É–≥–ª–æ–≤**: <—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ / –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ>  
        - **–ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è**: <–µ—Å–ª–∏ –µ—Å—Ç—å>  

        ‚ö†Ô∏è **–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã**:
        - <–æ–ø–∏—à–∏ —É—á–∞—Å—Ç–∫–∏ —Å —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è–º–∏>  
        
        üìä –í—ã–≤–æ–¥—ã:
        - –ò—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é –¥–æ 2 –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π  
        - –í—ã–≤–æ–¥—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º–∏ –∏ –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º–∏  
        - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è

        üìÅ **–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞** (–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏):
        {json.dumps(stats, indent=2)}
        """

    def _get_llm_response(self, prompt: str):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ LLM"""
        if self.provider == "openrouter":
            completion = self.client.chat.completions.create(
                extra_headers={
                    "HTTP-Referer": "https://sem.rybakov-k.ru/",
                    "X-Title": "ParticleAnalyzer",
                },
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )
            return completion
        elif self.provider == "huggingface":
            return self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )

    def _format_response(self, response) -> List[Tuple[None, str]]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ LLM"""
        if self.provider == "openrouter":
            analysis = response.choices[0].message.content
        elif self.provider == "huggingface":
            analysis = response.choices[0].message.content
        return [(None, analysis)]